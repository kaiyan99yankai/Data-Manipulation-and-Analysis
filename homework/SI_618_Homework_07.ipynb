{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-03T23:35:43.448137Z",
     "iopub.status.busy": "2022-04-03T23:35:43.447324Z",
     "iopub.status.idle": "2022-04-03T23:35:43.456411Z",
     "shell.execute_reply": "2022-04-03T23:35:43.455537Z",
     "shell.execute_reply.started": "2022-04-03T23:35:43.448100Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:35:43.463550Z",
     "iopub.status.busy": "2022-04-03T23:35:43.463316Z",
     "iopub.status.idle": "2022-04-03T23:35:43.476673Z",
     "shell.execute_reply": "2022-04-03T23:35:43.475980Z",
     "shell.execute_reply.started": "2022-04-03T23:35:43.463519Z"
    }
   },
   "outputs": [],
   "source": [
    "#input the data\n",
    "train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "test = pd.read_csv(\"../input/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:35:43.479035Z",
     "iopub.status.busy": "2022-04-03T23:35:43.478271Z",
     "iopub.status.idle": "2022-04-03T23:35:43.492236Z",
     "shell.execute_reply": "2022-04-03T23:35:43.491472Z",
     "shell.execute_reply.started": "2022-04-03T23:35:43.478986Z"
    }
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:35:43.493694Z",
     "iopub.status.busy": "2022-04-03T23:35:43.493089Z",
     "iopub.status.idle": "2022-04-03T23:35:43.510004Z",
     "shell.execute_reply": "2022-04-03T23:35:43.509149Z",
     "shell.execute_reply.started": "2022-04-03T23:35:43.493657Z"
    }
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the basic info of the training dataset and the test dataset, we can find that there is a lot of null values. Moreover, after reading the variable description, I find that some of the info may be useless, including the name and ticket. So that, we should firstly clean the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:35:43.512727Z",
     "iopub.status.busy": "2022-04-03T23:35:43.512148Z",
     "iopub.status.idle": "2022-04-03T23:35:43.521132Z",
     "shell.execute_reply": "2022-04-03T23:35:43.520420Z",
     "shell.execute_reply.started": "2022-04-03T23:35:43.512672Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1)\n",
    "test = test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:36:58.923861Z",
     "iopub.status.busy": "2022-04-03T23:36:58.923575Z",
     "iopub.status.idle": "2022-04-03T23:36:58.933518Z",
     "shell.execute_reply": "2022-04-03T23:36:58.932802Z",
     "shell.execute_reply.started": "2022-04-03T23:36:58.923828Z"
    }
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the age data, I would like to fill na with the median of the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:39:50.212448Z",
     "iopub.status.busy": "2022-04-03T23:39:50.211793Z",
     "iopub.status.idle": "2022-04-03T23:39:50.218088Z",
     "shell.execute_reply": "2022-04-03T23:39:50.217304Z",
     "shell.execute_reply.started": "2022-04-03T23:39:50.212411Z"
    }
   },
   "outputs": [],
   "source": [
    "train.Age.fillna(train.Age.median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:41:38.067260Z",
     "iopub.status.busy": "2022-04-03T23:41:38.066962Z",
     "iopub.status.idle": "2022-04-03T23:41:38.073820Z",
     "shell.execute_reply": "2022-04-03T23:41:38.073271Z",
     "shell.execute_reply.started": "2022-04-03T23:41:38.067218Z"
    }
   },
   "outputs": [],
   "source": [
    "train.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the embarked data, since it is the categorical data, I would fill the na with the most common category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:43:43.583985Z",
     "iopub.status.busy": "2022-04-03T23:43:43.583473Z",
     "iopub.status.idle": "2022-04-03T23:43:43.589828Z",
     "shell.execute_reply": "2022-04-03T23:43:43.588667Z",
     "shell.execute_reply.started": "2022-04-03T23:43:43.583951Z"
    }
   },
   "outputs": [],
   "source": [
    "train.Embarked.fillna(train.Embarked.value_counts().index[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:43:58.579111Z",
     "iopub.status.busy": "2022-04-03T23:43:58.578635Z",
     "iopub.status.idle": "2022-04-03T23:43:58.588250Z",
     "shell.execute_reply": "2022-04-03T23:43:58.587361Z",
     "shell.execute_reply.started": "2022-04-03T23:43:58.579074Z"
    }
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test data, I would use the same data as the train data to fill the na, since I think we should only extract info from the training set to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:45:32.393762Z",
     "iopub.status.busy": "2022-04-03T23:45:32.393469Z",
     "iopub.status.idle": "2022-04-03T23:45:32.403705Z",
     "shell.execute_reply": "2022-04-03T23:45:32.402984Z",
     "shell.execute_reply.started": "2022-04-03T23:45:32.393728Z"
    }
   },
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:46:37.850551Z",
     "iopub.status.busy": "2022-04-03T23:46:37.850010Z",
     "iopub.status.idle": "2022-04-03T23:46:37.856629Z",
     "shell.execute_reply": "2022-04-03T23:46:37.855870Z",
     "shell.execute_reply.started": "2022-04-03T23:46:37.850512Z"
    }
   },
   "outputs": [],
   "source": [
    "test.Age.fillna(train.Age.median(), inplace = True)\n",
    "test.Fare.fillna(train.Fare.median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:46:48.194684Z",
     "iopub.status.busy": "2022-04-03T23:46:48.194181Z",
     "iopub.status.idle": "2022-04-03T23:46:48.201795Z",
     "shell.execute_reply": "2022-04-03T23:46:48.201215Z",
     "shell.execute_reply.started": "2022-04-03T23:46:48.194650Z"
    }
   },
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can go through the EDA, and try to find some useful pattern from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-03T23:49:18.730386Z",
     "iopub.status.busy": "2022-04-03T23:49:18.729986Z",
     "iopub.status.idle": "2022-04-03T23:49:18.734960Z",
     "shell.execute_reply": "2022-04-03T23:49:18.734156Z",
     "shell.execute_reply.started": "2022-04-03T23:49:18.730354Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I would like to go through each categorcal feature and find their relationship with the survivied data, and hopefully we can find some pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:05:37.713261Z",
     "iopub.status.busy": "2022-04-04T00:05:37.712824Z",
     "iopub.status.idle": "2022-04-04T00:05:37.716939Z",
     "shell.execute_reply": "2022-04-04T00:05:37.716376Z",
     "shell.execute_reply.started": "2022-04-04T00:05:37.713230Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_col = train.columns.drop(['Survived', 'Age', 'Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:11:27.861144Z",
     "iopub.status.busy": "2022-04-04T00:11:27.859925Z",
     "iopub.status.idle": "2022-04-04T00:11:29.068858Z",
     "shell.execute_reply": "2022-04-04T00:11:29.068024Z",
     "shell.execute_reply.started": "2022-04-04T00:11:27.861090Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(cat_col), figsize = (20, 5))\n",
    "for ind, cat in enumerate(cat_col):\n",
    "    sns.barplot(ax = axes[ind], data = train, x = cat, y = 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the barplots, we find that the Sex, Pclass, and Embarkerd may be crucial to the ratio of survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:24:02.339143Z",
     "iopub.status.busy": "2022-04-04T00:24:02.338824Z",
     "iopub.status.idle": "2022-04-04T00:24:02.754518Z",
     "shell.execute_reply": "2022-04-04T00:24:02.753904Z",
     "shell.execute_reply.started": "2022-04-04T00:24:02.339110Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.displot(data = train, x = 'Age', hue = 'Survived', kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the distribution of the age and survival ratio, we find that those who are in their 20-40 have the lowest survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:24:29.376361Z",
     "iopub.status.busy": "2022-04-04T00:24:29.375780Z",
     "iopub.status.idle": "2022-04-04T00:24:29.779573Z",
     "shell.execute_reply": "2022-04-04T00:24:29.778969Z",
     "shell.execute_reply.started": "2022-04-04T00:24:29.376314Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.displot(data = train, x = 'Fare', hue = 'Survived', kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, those who have the cheaper tickets, are more likely to not survive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the EDA, I would like to add a new feature to the dataset which indicate if the passenger is bwteen 20 and 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:33:00.132587Z",
     "iopub.status.busy": "2022-04-04T00:33:00.131724Z",
     "iopub.status.idle": "2022-04-04T00:33:00.138965Z",
     "shell.execute_reply": "2022-04-04T00:33:00.138072Z",
     "shell.execute_reply.started": "2022-04-04T00:33:00.132546Z"
    }
   },
   "outputs": [],
   "source": [
    "test['20_40'] = test.Age.apply(lambda x: 1 if x>=20 and x<=40 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:33:27.834989Z",
     "iopub.status.busy": "2022-04-04T00:33:27.834162Z",
     "iopub.status.idle": "2022-04-04T00:33:27.840818Z",
     "shell.execute_reply": "2022-04-04T00:33:27.840002Z",
     "shell.execute_reply.started": "2022-04-04T00:33:27.834930Z"
    }
   },
   "outputs": [],
   "source": [
    "train['20_40'] = train.Age.apply(lambda x: 1 if x>=20 and x<=40 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can do the machine learning part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, since the survive rate is not balanced, we should use sss to split the data as the ratio of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:37:52.771122Z",
     "iopub.status.busy": "2022-04-04T00:37:52.770687Z",
     "iopub.status.idle": "2022-04-04T00:37:52.775442Z",
     "shell.execute_reply": "2022-04-04T00:37:52.774923Z",
     "shell.execute_reply.started": "2022-04-04T00:37:52.771090Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:39:21.396683Z",
     "iopub.status.busy": "2022-04-04T00:39:21.395836Z",
     "iopub.status.idle": "2022-04-04T00:39:21.405590Z",
     "shell.execute_reply": "2022-04-04T00:39:21.404745Z",
     "shell.execute_reply.started": "2022-04-04T00:39:21.396639Z"
    }
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in sss.split(train, train['Survived']):\n",
    "    train_set = train.iloc[train.index.intersection(train_index)]\n",
    "    test_set = train.iloc[train.index.intersection(test_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:41:19.280931Z",
     "iopub.status.busy": "2022-04-04T00:41:19.280643Z",
     "iopub.status.idle": "2022-04-04T00:41:19.288668Z",
     "shell.execute_reply": "2022-04-04T00:41:19.287851Z",
     "shell.execute_reply.started": "2022-04-04T00:41:19.280901Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set.Survived.value_counts()[1]/train_set.Survived.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:41:12.390327Z",
     "iopub.status.busy": "2022-04-04T00:41:12.389918Z",
     "iopub.status.idle": "2022-04-04T00:41:12.406432Z",
     "shell.execute_reply": "2022-04-04T00:41:12.404949Z",
     "shell.execute_reply.started": "2022-04-04T00:41:12.390292Z"
    }
   },
   "outputs": [],
   "source": [
    "test_set.Survived.value_counts()[1]/test_set.Survived.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:54:40.927381Z",
     "iopub.status.busy": "2022-04-04T00:54:40.927066Z",
     "iopub.status.idle": "2022-04-04T00:54:40.934680Z",
     "shell.execute_reply": "2022-04-04T00:54:40.933648Z",
     "shell.execute_reply.started": "2022-04-04T00:54:40.927340Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set_X = train_set.drop('Survived', axis = 1)\n",
    "train_set_y = train_set['Survived']\n",
    "test_set_X = test_set.drop('Survived', axis = 1)\n",
    "test_set_y = test_set['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we should do some preprocessing to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:50:05.077432Z",
     "iopub.status.busy": "2022-04-04T00:50:05.077128Z",
     "iopub.status.idle": "2022-04-04T00:50:05.091961Z",
     "shell.execute_reply": "2022-04-04T00:50:05.090991Z",
     "shell.execute_reply.started": "2022-04-04T00:50:05.077403Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:54:51.677229Z",
     "iopub.status.busy": "2022-04-04T00:54:51.676573Z",
     "iopub.status.idle": "2022-04-04T00:54:51.683423Z",
     "shell.execute_reply": "2022-04-04T00:54:51.682833Z",
     "shell.execute_reply.started": "2022-04-04T00:54:51.677183Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "num_attribs = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat_attribs = list(train_set_X.drop(num_attribs, axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:55:05.107689Z",
     "iopub.status.busy": "2022-04-04T00:55:05.107277Z",
     "iopub.status.idle": "2022-04-04T00:55:05.130003Z",
     "shell.execute_reply": "2022-04-04T00:55:05.129064Z",
     "shell.execute_reply.started": "2022-04-04T00:55:05.107640Z"
    }
   },
   "outputs": [],
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "train_X_prepared = full_pipeline.fit_transform(train_set_X)\n",
    "test_X_prepared = full_pipeline.transform(test_set_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:37:23.923160Z",
     "iopub.status.busy": "2022-04-04T00:37:23.922647Z",
     "iopub.status.idle": "2022-04-04T00:37:23.929153Z",
     "shell.execute_reply": "2022-04-04T00:37:23.928643Z",
     "shell.execute_reply.started": "2022-04-04T00:37:23.923114Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:35:39.764683Z",
     "iopub.status.busy": "2022-04-04T00:35:39.764410Z",
     "iopub.status.idle": "2022-04-04T00:35:39.770913Z",
     "shell.execute_reply": "2022-04-04T00:35:39.769966Z",
     "shell.execute_reply.started": "2022-04-04T00:35:39.764650Z"
    }
   },
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T00:56:39.864137Z",
     "iopub.status.busy": "2022-04-04T00:56:39.863555Z",
     "iopub.status.idle": "2022-04-04T00:56:47.298320Z",
     "shell.execute_reply": "2022-04-04T00:56:47.297778Z",
     "shell.execute_reply.started": "2022-04-04T00:56:39.864091Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(train_X_prepared, train_set_y)\n",
    "    y_pred = clf.predict(test_X_prepared)\n",
    "    accuracy = clf.score(test_X_prepared, test_set_y)\n",
    "    print(\"%s Accuracy: %.2f%%\" % (name,accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find that the Gaussian Process Accuracy and Nearest Neighbors Accuracy are highest, I would choose the Gaussian Process model and check the output accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T01:06:21.075490Z",
     "iopub.status.busy": "2022-04-04T01:06:21.074482Z",
     "iopub.status.idle": "2022-04-04T01:06:26.820426Z",
     "shell.execute_reply": "2022-04-04T01:06:26.819435Z",
     "shell.execute_reply.started": "2022-04-04T01:06:21.075447Z"
    }
   },
   "outputs": [],
   "source": [
    "model = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "model.fit(train_X_prepared, train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T01:08:24.303543Z",
     "iopub.status.busy": "2022-04-04T01:08:24.303135Z",
     "iopub.status.idle": "2022-04-04T01:08:24.313036Z",
     "shell.execute_reply": "2022-04-04T01:08:24.312354Z",
     "shell.execute_reply.started": "2022-04-04T01:08:24.303511Z"
    }
   },
   "outputs": [],
   "source": [
    "transformed_test = full_pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T01:12:18.680510Z",
     "iopub.status.busy": "2022-04-04T01:12:18.679977Z",
     "iopub.status.idle": "2022-04-04T01:12:18.715023Z",
     "shell.execute_reply": "2022-04-04T01:12:18.714180Z",
     "shell.execute_reply.started": "2022-04-04T01:12:18.680475Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(transformed_test)\n",
    "submission=pd.read_csv(\"../input/titanic/gender_submission.csv\")\n",
    "submission.Survived = predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "display(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final accuray is 0.76794"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
